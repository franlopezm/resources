# M320 - Data Modeling
Learn everything you need to know about data modeling for MongoDB.

## Introduction to Data Modeling
### The document model in MongoDB
- MongoDB stores data as Documents. [Document structure][documentStructure]
- Document fields can be values, embedded documents, or arrays of values and documents.
- MongoDB is a flexive Schema database.
- MongoDB documents are stored as BSON documents.
- [Supported datatypes][supportDatatypes]

Example:

```json
{
    "firstName": "John",
    "lastName": "Doe",
    "age": 25,
    "address": {
        "city": "Capitol",
        "state": "Moosylvania",
        "street": "One"
    },
    "phones": [
        "987654123", "389748323"
    ]
}
```


### Constraints in data modeling

- Keep the frequently used Documents in RAM
- Keep the Indexes in RAM
- Prefer SSD to HDD
- Infrequently data can use HDD
- The nature of your dataset and hardware define the need to model your data
  - It is important to identify those exact constraints and their impact to create a better model
  - As your software and the technological landscape change, your model should be re-evaluated and updated accordingly.
- Avoid [Transactions][transactions]
  - [Transactions videos][transactionVideos]


### Data modeling methodology diagram
- Workload
  - Data size, important reads and writes
- Relationships
  - Identify them, link or embed the related entities
- Patterns
  - Apply the ones for needed optimizations

![Data modeling methodology diagram](/images/m320-methodology-diagram.png ':size=300xHEIGHT')


### Model for simplicity or Performance
**Modeling for Simplicity Diagram**

![Modeling for Simplicity Diagram](/images/m320-modeling-simplicity-diagram.png ':size=300xHEIGHT')

**Modeling for Performance Diagram**

![Modeling for Simplicity Diagram](/images/m320-modeling-performance-diagram.png ':size=300xHEIGHT')

**Modeling for a Mix of Simplicity and Performance Diagram**

![Modeling for Simplicity Diagram](/images/m320-modeling-mix-diagram.png ':size=300xHEIGHT')

**Summary of Modeling Approaches**

![Modeling for Simplicity Diagram](/images/m320-modeling-summary.png ':size=300xHEIGHT')


### Identifying the workload
- Quantify and qualify the queries as much as you can.
- Few CRUD operations will drive the design.

Examples of data with their desired durability

| Type of data                      | Durability      | MongoDB notation |
| --------------------------------- | --------------- | ---------------- |
| Money                             | majority        | w=majority       |
| Account information               | majority        | w=majority       |
| ...anything that you can't lose   | majority        | w=majority       |
| Log data                          | one node        | w=1              |
| Sensor data                       | one node        | w=1              |
| Stock quotes, few per second data | fire and forget | w=0              |



## Relationships
### Types and Cardinality
- Common Relationships
  - one to one (1-1)
  - one to many (1-N)
  - many to many (N-N)
  - one to zillions (1-[minimum, likely, maximum]) Used in Big data.

### One to Many
- Embed
  - in the "one" side
    - The documents from the "many" side are embedded
    - Most common representation for: simple applications or few documents to embed
    - Need to process main object and the N related documents together
    - Indexing is done on the array
  - in the "many" side
    - Less often used
    - Useful if "many" side is queried more often than the "one" side
    - Embedded object is duplicated, duplication may be preferable for dynamic objects
  - Usually, embedding in the entity the most queried
- Reference
  - in the "one" side
    - Array of references
    - Allows for large documents and a high count of these
    - List of references available when retrieving the main object
    - Cascade deletes are not supported by MongoDB and must be managed by the application
  - in the "many" side
    - Preferred representation using references
    - Allows for large documents and a high count of these
    - No need to manage the references on the "one" side.
  - Usually, referencing in the "many" side

### Many to Many
- Embed
  - Array of subdocuments in the "many" side
    - The documents from the less queried side are embedded
    - Results in duplication
    - Keep "source" for the embedded documents in another collection
    - Indexing is done on the array
  - Array of subdocuments in the other "many" side
  - Usually, only the most queried side is considered
  - Prefer embedding on the most queried side
  - Prefer embedding for information that is primarily static over time and may profit from duplication
- Reference
  - Array of references in one "many" side
    - Array of references to the documents of the other collection
    - References readily available upon first query on the "main" collection
  - Array of references in the other "many" side
    - Array of references to the documents of the other collection
    - Need a second query to get more information
  - Prefer referencing over embedding to avoid managing duplication

### One to One
- Prefer embedding over referencing for simplicity
- Embed
  - Fields at same level
  - Grouping in sub-documents
- Reference
  - Same identifier in both documents
  - In the main "one" side
  - In the secondary "one" side
  - Add complexity
  - Possible performance improvements with:
    - smaller disk access
    - smaller amount of RAM needed

### One to Zillions
- Reference
  - in the "many/zillions" side


## Patterns
More about [BSON Types][bsonTypes] and [JSON Schema][jsonSchema].

### Handling Duplication, Staleness and Integrity
These are the three most important concepts:

- Handling Duplication
  - Duplicatin data across documents
  - Why?
    - Result of embedding information in a given document for faster access.
  - Concern?
    - Challenge for correctness and consistency.
- Handling Staleness
  - Accepting staleness in some pieces of data
  - Why?
    - New events come along at such a rate that updating some data constantly causes performance issues.
  - Concern?
    - Data quality and reliability
- Handling Referential Integrity
  - Writing extra application side logic to ensure referencial integrity
  - Why?
    - Linking information between documents or tables.
    - No support for cascading deletes
  - Concern?
    - Challenge for correctness and consistency

For a given piece of data:
- Should or could the information be duplicated or not?
  - Resolve with bulk updates
- What is the tolerated or acceptable staleness?
  - Resolve with updates bases on [change streams][changeStreams]
- Which pieces of data require referential integrity?
  - Resolve or prevent the inconsistencies with [change streams][changeStreams] or transactions

### Attribute Pattern
Orthogonal pattern to polymorphism

- Problem
  - Lots of similar fields
  - Want to search across many fields at once
  - Fields present in only a small subset of documents
- Solution
  - Break the field/value into a sub-document with:
    - fieldA: field
    - fieldB: value
  - Example:
    - from `{ color: "blue", size: "large" }`
    - to `[{ k: "color", v: "blue" }, { k: "color", v: "large" }]`
- Use cases Examples
  - Characteristics of a product
  - Rare/unpredictable fields
  - Commom characteristics
  - Set of fields all having same value type
    - List of dates
- Benefits and Trade-offs
  - Easier to index
  - Allow for non-deterministic field names
  - Ability to qualify the relationship of the original field and value
  - Reduces number of indexes

**Example**

![Attribute Pattern](/images/m320-attribute-pattern.png ':size=320xHEIGHT')

### Extended Reference Pattern
- Problem
  - Too many repetitive joins
- Solution
  - Identify fields on the lookup side
  - Bring those fields into the main object
- Use cases Examples
  - Catalog
  - Mobile Applications
  - Reat-Time Analytics
- Benefits and Trade-offs
  - Faster reads
  - Reduce number of joins and lookups
  - May introduce lots of duplication if extended reference contains fields that mutate a lot

### Subset Pattern
- Problem
  - Working set is too big
  - Lot of pages are evicted from memory
  - A large part of documents ir rarely needed
- Solution
  - Split the collection in 2 collections
    - Most used part of documents
    - Less used part of documents
  - Duplicate part of a 1-N or N-N relationship that is often used in the most used side
- Use cases Examples
  - List of reviews for a product
  - List of comments on an article
  - List of actors in a movie
- Benefits and Trade-offs
  - Smaller working set, as often used documents are smaller
  - Shorter disk access for bringing in additional documents from the most used collection
  - More round trips to the server
  - A little more space used on disk


[documentStructure]: https://docs.mongodb.com/manual/core/data-modeling-introduction/#document-structure
[supportDatatypes]: https://docs.mongodb.com/master/reference/bson-types/
[transactions]: https://docs.mongodb.com/manual/core/transactions/
[transactionVideos]: https://www.mongodb.com/transactions
[bsonTypes]: https://docs.mongodb.com/manual/reference/bson-types
[jsonSchema]: https://json-schema.org
[changeStreams]: https://docs.mongodb.com/manual/changeStreams